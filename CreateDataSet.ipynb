{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshal292004/Harshal292004/blob/main/CreateDataSet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U -q transformers sentence-transformers bitsandbytes accelerate langchain_groq langgraph wikipedia  langchain-community langchain-experimental langchain-huggingface pypdf\n"
      ],
      "metadata": {
        "id": "-CaXZxlwxuIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eba72ff-bdd5-4c92-e2a8-b9fe1798c762"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "# Standard library imports\n",
        "import json\n",
        "import asyncio\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "from typing import List, Optional, Annotated,Dict\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "# Pydantic imports\n",
        "from pydantic import BaseModel, Field, field_validator,validator\n",
        "\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import AnyMessage, AIMessage, HumanMessage, ToolMessage\n",
        "from langchain_core.runnables import RunnableLambda, chain as as_runnable, RunnableConfig\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# LangChain community imports\n",
        "from langchain_community.vectorstores import InMemoryVectorStore\n",
        "from langchain_community.retrievers import WikipediaRetriever\n",
        "from langchain_community.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
        "from langchain_community.tools import DuckDuckGoSearchResults\n",
        "\n",
        "# HuggingFace imports\n",
        "from langchain_huggingface import  ChatHuggingFace,HuggingFaceEndpoint,HuggingFaceEmbeddings\n",
        "from huggingface_hub import  login\n",
        "\n",
        "# Groq imports\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# LangGraph imports\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.pregel import RetryPolicy\n",
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "# IPython Display\n",
        "from IPython.display import Image, display\n",
        "\n",
        "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "toLP9w14Of6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25c32c31-49f1-4db4-fe4e-cca201ff2413"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **USING  ChatGroq**"
      ],
      "metadata": {
        "id": "5V9610n4JL0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm=ChatGroq(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    api_key=\"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\",\n",
        ")"
      ],
      "metadata": {
        "id": "vL1PGmzMJLP7"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some UTILITY FUNCTIONS"
      ],
      "metadata": {
        "id": "UBXY-dNrZa50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recursively_get_pdf_files(directory):\n",
        "    pdf_files = []\n",
        "    try:\n",
        "        if os.path.isfile(directory) and directory.endswith('.pdf'):\n",
        "            pdf_files.append(directory)\n",
        "        elif os.path.isdir(directory):\n",
        "            for file in os.listdir(directory):\n",
        "                full_path = os.path.join(directory, file)\n",
        "                pdf_files.extend(recursively_get_pdf_files(full_path))\n",
        "    except Exception as e:\n",
        "        print(f\"Error accessing {directory}: {e}\")\n",
        "    return pdf_files\n"
      ],
      "metadata": {
        "id": "z5duPna2TJim"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pdf(pdf_path):\n",
        "  loader = PyPDFLoader(pdf_path)\n",
        "  pdf_page_list=loader.load()\n",
        "  return pdf_page_list"
      ],
      "metadata": {
        "id": "sVAaxKqHgSRO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pdfs(list_of_pdf_paths):\n",
        "  pdf_list=[]\n",
        "  for pdf_path in list_of_pdf_paths:\n",
        "    pdf_list.append(load_pdf(pdf_path))\n",
        "  return pdf_list"
      ],
      "metadata": {
        "id": "-wRSfCndYemj"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings_model(model_name=\"sentence-transformers/all-mpnet-base-v2\",model_kwargs = {'device': 'cuda'},  encode_kwargs = {'normalize_embeddings': False}):\n",
        "  embeddings_model = HuggingFaceEmbeddings(\n",
        "      model_name=model_name,\n",
        "      model_kwargs=model_kwargs,\n",
        "      encode_kwargs=encode_kwargs\n",
        "  )\n",
        "  return embeddings_model"
      ],
      "metadata": {
        "id": "ScH4jtswm2XX"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_model= get_embeddings_model()"
      ],
      "metadata": {
        "id": "7OHnkvJXf1XB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_spillter= SemanticChunker(embeddings_model)"
      ],
      "metadata": {
        "id": "agKY6E1dZrmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_pdf(pdf_page_list):\n",
        "  pdf_spllited=text_spillter.split_documents(pdf_page_list)\n",
        "  return pdf_spllited"
      ],
      "metadata": {
        "id": "gZIERwskgymK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_documents(pdf_list):\n",
        "  splitted_pdf_list =[]\n",
        "  for pdf in pdf_list:\n",
        "    docs_spllited=split_pdf(pdf)\n",
        "    splitted_pdf_list .append(docs_spllited)\n",
        "  return splitted_pdf_list"
      ],
      "metadata": {
        "id": "OmiwfMmm9IOk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agents"
      ],
      "metadata": {
        "id": "xcoq_WCjZX4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ScoreDetails(BaseModel):\n",
        "\n",
        "  score:float = Field(\n",
        "      description=\"Score of the chunk or the paper\"\n",
        "  )\n",
        "  justification:str = Field(\n",
        "      description=\"Justification of the chunk or the paper\"\n",
        "  )\n",
        "\n",
        "  @validator('score')\n",
        "  def score_must_be_between_0_and_10(cls, v):\n",
        "    if v < 0 or v > 10:\n",
        "      raise ValueError('score must be between 0 and 10')\n",
        "    return v\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cipSHODtY0rI",
        "outputId": "8ee43b0b-1bec-466c-b1a7-43a9e119be33"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-131-7db4f4c3a788>:10: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  @validator('score')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PaperEvaluation(BaseModel):\n",
        "  paper_id:str= Field(\n",
        "      description=\"Unique identifier for the paper\"\n",
        "  )\n",
        "  methodology:ScoreDetails= Field(\n",
        "      description=\"Methodology score and justification of the chunk or the paper\"\n",
        "  )\n",
        "  coherence:ScoreDetails = Field(\n",
        "      description=\"Coherence score and justification of the chunk or the paper\"\n",
        "  )\n",
        "  evidenceScore:ScoreDetails= Field(\n",
        "      description=\"Evidence score and justification of the chunk or the paper\"\n",
        "  )\n",
        "  technicalScore:ScoreDetails= Field(\n",
        "      description=\"Technical score and justification of the chunk or the paper\"\n",
        "  )\n",
        "  innovationScore:ScoreDetails= Field(\n",
        "      description=\"Innovation score and justification of the chunk or the paper\"\n",
        "  )\n",
        "  Publishable:bool = Field(\n",
        "      description=\"Whether the paper is publishable or not\"\n",
        "  )\n",
        "  justification:str = Field(\n",
        "      description=\"Overall Justification for the classification of chunk or paper\"\n",
        "  )"
      ],
      "metadata": {
        "id": "8GZO70GCZVT0"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_a_analysis_of_chunk = ChatPromptTemplate([\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are an intelligent assistant tasked with analyzing research papers to determine their publishability. Your role is to provide a detailed analysis of why a paper is labeled as publishable or non-publishable based on the quality of the paper.\"\n",
        "    ),\n",
        "    (\n",
        "        \"human\",\n",
        "        \"\"\"\n",
        "        You will evaluate the content of a semantic chunk of a research paper at a time,\\\n",
        "        as you have limitations on processing large texts.\n",
        "        You will not be labeling the papers yourself,\\\n",
        "        but rather analyzing the provided labels based on previously labeled examples.\n",
        "        Your analysis should focus on the following parameters:\n",
        "        - Methodology\n",
        "        - Coherence\n",
        "        - Evidence\n",
        "        - Techincal\n",
        "        - Inovative\n",
        "\n",
        "        You will be provided with the following information:\n",
        "        - The content of the chunk: {content_of_chunk}\n",
        "        - The publishability label of the paper: {publishable}\n",
        "        - The unique identifier for the paper: {paper_id}\n",
        "\n",
        "        Please provide a comprehensive analysis based on the above parameters, explaining why the paper has been labeled as it is.\n",
        "        Score Should be strictly in the range 0 to  10 (fractions allowed)\n",
        "    \"\"\"\n",
        "    )\n",
        "])"
      ],
      "metadata": {
        "id": "tCNMHAaSKlW2"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_a_final_analysis_prompt = ChatPromptTemplate([\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are an intelligent assistant tasked with analyzing research papers to determine their publishability. Your role is to provide a detailed analysis of why a paper is labeled as publishable or non-publishable based on the quality of the paper.\"\n",
        "    ),\n",
        "    (\n",
        "        \"human\",\n",
        "        \"\"\"\n",
        "        You will evaluate a research paper based on predefined criteria that have been established beforehand.\n",
        "        You will collaborate with an assistant researcher who has studied each chunk of the paper and provided scores and justifications.\n",
        "\n",
        "        Your task is to:\n",
        "        - Understand the provided scores as a list of information.\n",
        "        - Determine the average score you want to assign to the paper.\n",
        "        - Provide justifications for your score, negotiating with the assistant where necessary.\n",
        "\n",
        "        You will be provided with a list of Pydantic models that contain the scores and justifications for each field.\n",
        "        Use this information to judge the entire paper and provide an average assessment for each criterion.\n",
        "        Note that you can give average score value between 0 and 10 (fractions allowed)\n",
        "        {evaluations_summary}\n",
        "\n",
        "        Based on the evaluations provided, please summarize the overall quality of the papers and provide any recommendations for improvement.\n",
        "        \"\"\"\n",
        "    )\n",
        "])\n"
      ],
      "metadata": {
        "id": "5DiaU9T7MmC2"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_paper(doc,paper_id,publishable=False):\n",
        "  analysis_list=[]\n",
        "  for d in doc:\n",
        "    content=d.page_content\n",
        "    if content==\"\" or len(content)<100:\n",
        "      continue\n",
        "    chunk_with_publishiabllity_and_paper_id = {\n",
        "        \"content_of_chunk\": content,\n",
        "        \"publishable\": publishable,\n",
        "        \"paper_id\":paper_id\n",
        "    }\n",
        "    answer=gen_a_analysis_of_chunk_chain.invoke(chunk_with_publishiabllity_and_paper_id)\n",
        "    analysis_list.append(answer)\n",
        "\n",
        "  return analysis_list"
      ],
      "metadata": {
        "id": "EE5-J7r4Kt2V"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Develop a framework to label a single paper with just the path of the pdf and the publishablity"
      ],
      "metadata": {
        "id": "GdyK4QqQbu89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "\n",
        "# Generate a random UUID\n",
        "random_id = uuid.uuid4()\n",
        "print(random_id)\n"
      ],
      "metadata": {
        "id": "UP9oNgjXi8bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_paper(path_of_pdf,publishable=False,paper_id=\"\"):\n",
        "  # load the pdf\n",
        "  pages_loaded=load_pdf(path_of_pdf)\n",
        "  # split the document semantically\n",
        "  # build a framework where you can change on the type of splliting is used\n",
        "  spllited_pdf=split_pdf(pages_loaded)\n",
        "\n",
        "  #Now Kick in the Agentic workflow of actually labelling the papers\n",
        "  #Analyze the chunks based on the evaluation schema predefined\n",
        "  # either paper_id is provided or just create one :\n",
        "\n",
        "  # Generate a random UUID\n",
        "  if(paper_id==\"\"):\n",
        "    random_id = uuid.uuid4()\n",
        "    paper_id=str(random_id)\n",
        "\n",
        "\n",
        "  analysis_list=analyze_paper(spllited_pdf,publishable=publishable,paper_id=paper_id)\n",
        "\n",
        "  #Now here we have got the justification and scoors on the predefined critarieas\n",
        "  #We can also let user define the criteria or fall back to default\n",
        "\n",
        "  #Now use the merge and devide for devicing the actuall papper labellings\n",
        "\n",
        "  final_analysis = merge_and_create_summary_recurrsively(analysis_list, 0, len(analysis_list) - 1)\n",
        "\n",
        "  return final_analysis\n"
      ],
      "metadata": {
        "id": "aXOwvYzBfhpo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#built a ui so that we can easily show case the results of labelliong a directory as well\n",
        "\n",
        "def label_directory(directory='/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable',list_of_publisability=[True]):\n",
        "  list_of_files=recursively_get_pdf_files('/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable')\n",
        "  # for now consider all of them to be publoshable\n",
        "  load_pdfs\n"
      ],
      "metadata": {
        "id": "rywGIU2LjxZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_files=recursively_get_pdf_files('/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable')"
      ],
      "metadata": {
        "id": "M-Mf-4NHT6Ei"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_list= load_docs(list_of_files)"
      ],
      "metadata": {
        "id": "mHwzhlAxUcfD"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_spillter= SemanticChunker(embeddings_model)"
      ],
      "metadata": {
        "id": "SsXMy7QtoDmm"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spllited_docs_list=split_documents(document_list)"
      ],
      "metadata": {
        "id": "NhaqFizHw6i0"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_a_paper(pdf_path,paper_id,publishable=False):\n",
        "  pass"
      ],
      "metadata": {
        "id": "EkMPHXPSZkq7"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_a_directory(directory):\n",
        "  pass"
      ],
      "metadata": {
        "id": "zkRco9BqaERq"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_with_publishiabllity_and_paper_id = {\n",
        "    \"content_of_chunk\": content,\n",
        "   \"publishable\": True,\n",
        "    \"paper_id\": \"R006\"\n",
        " }"
      ],
      "metadata": {
        "id": "N0dV4PcsC1qb"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_a_analysis_of_chunk_chain= gen_a_analysis_of_chunk | llm.with_structured_output(PaperEvaluation)"
      ],
      "metadata": {
        "id": "7y_bm6fwPJd7"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_value = gen_a_analysis_of_chunk.invoke(\n",
        "    chunk_with_publishiabllity_and_paper_id\n",
        ")"
      ],
      "metadata": {
        "id": "aRn-9vYfgY4H"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer=gen_a_analysis_of_chunk_chain.invoke(chunk_with_publishiabllity_and_paper_id)"
      ],
      "metadata": {
        "id": "RDkS2omSLzsB"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analysis_list=analyze_paper(spllited_docs_list[0],paper_id=\"R006\",publishable=True)"
      ],
      "metadata": {
        "id": "xIqpbrAHMdjF"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(analysis_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epVC5f8nMxk8",
        "outputId": "301cd378-59bd-47e0-eade-65ab3e6d732f"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_list_beautifully(list_of_stuff):\n",
        "  for index,stuff in enumerate(list_of_stuff):\n",
        "    print(\"-\"*20)\n",
        "    print(\"Stuff Number \" + str(index+1))\n",
        "    print(\"-\"*20)\n",
        "    print(stuff)\n",
        "    print(\"-\"*20)"
      ],
      "metadata": {
        "id": "qfLHIBaCODn6"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_analysis_summary(evaluations):\n",
        "  formatted_evaluations = []\n",
        "  for evaluation in evaluations:\n",
        "      formatted_evaluations.append(\n",
        "          f\"Paper ID: {evaluation.paper_id}\\n\"\n",
        "          f\"Methodology Score: {evaluation.methodology.score} - Justification: {evaluation.methodology.justification}\\n\"\n",
        "          f\"Coherence Score: {evaluation.coherence.score} - Justification: {evaluation.coherence.justification}\\n\"\n",
        "          f\"Evidence Score: {evaluation.evidenceScore.score} - Justification: {evaluation.evidenceScore.justification}\\n\"\n",
        "          f\"Technical Score: {evaluation.technicalScore.score} - Justification: {evaluation.technicalScore.justification}\\n\"\n",
        "          f\"Innovation Score: {evaluation.innovationScore.score} - Justification: {evaluation.innovationScore.justification}\\n\"\n",
        "          f\"Publishable: {evaluation.Publishable}\\n\"\n",
        "          f\"Overall Justification: {evaluation.justification}\\n\"\n",
        "          \"----------------------------------------\\n\"\n",
        "      )\n",
        "  evaluations_summary = \"\\n\".join(formatted_evaluations)\n",
        "  return evaluations_summary"
      ],
      "metadata": {
        "id": "xEFFlL6dTAMF"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_a_final_analysis_chain=gen_a_final_analysis_prompt|llm.with_structured_output(PaperEvaluation)"
      ],
      "metadata": {
        "id": "aHo3VwP1TdnG"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_final_analysis(analysis_list):\n",
        "  evaluations_summary = get_analysis_summary(analysis_list)\n",
        "  final_analysis= gen_a_final_analysis_chain.invoke(evaluations_summary)\n",
        "  return final_analysis"
      ],
      "metadata": {
        "id": "K4fBjqt7Tbkq"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def merge_and_create_summary_recurrsively(analysis_list, left, right, wait_time=2):\n",
        "    \"\"\"\n",
        "    Recursively summarizes the analysis list using divide-and-conquer with a wait time between calls.\n",
        "\n",
        "    Parameters:\n",
        "    - analysis_list: List of analyses to be summarized.\n",
        "    - left: Starting index of the current sublist.\n",
        "    - right: Ending index of the current sublist.\n",
        "    - wait_time: Time to wait (in seconds) between summarization calls.\n",
        "\n",
        "    Returns:\n",
        "    - Summarized analysis for the specified range.\n",
        "    \"\"\"\n",
        "    # Base case: If the range is small enough, summarize directly\n",
        "    if right - left + 1 <= 4:  # At most 4 items\n",
        "        sublist = analysis_list[left:right + 1]\n",
        "        time.sleep(wait_time)  # Introduce wait time before calling the model\n",
        "        return get_final_analysis(sublist)\n",
        "\n",
        "    # Recursive division\n",
        "    mid = (left + right) // 2\n",
        "    left_summary = merge_and_create_summary_recurrsively(analysis_list, left, mid, wait_time)\n",
        "    time.sleep(wait_time)  # Wait before processing the next half\n",
        "    right_summary = merge_and_create_summary_recurrsively(analysis_list, mid + 1, right, wait_time)\n",
        "\n",
        "    # Combine the summaries of the left and right halves\n",
        "    time.sleep(wait_time)  # Wait before combining summaries\n",
        "    return get_final_analysis([left_summary, right_summary])\n"
      ],
      "metadata": {
        "id": "cXy6eNE_UkzP"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_summary = merge_and_create_summary_recurrsively(analysis_list, 0, len(analysis_list) - 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "s1eH8Ea5TatI",
        "outputId": "47b95594-bfd6-4dd4-d6b7-71b012b2b01b"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "2 validation errors for PaperEvaluation\nevidenceScore.score\n  Input should be a valid integer, got a number with a fractional part [type=int_from_float, input_value=7.67, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.10/v/int_from_float\ntechnicalScore.score\n  Input should be a valid integer, got a number with a fractional part [type=int_from_float, input_value=8.67, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.10/v/int_from_float",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-119-c5c220cdd929>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_and_create_summary_recurrsively\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-115-312375068bdf>\u001b[0m in \u001b[0;36mmerge_and_create_summary_recurrsively\u001b[0;34m(analysis_list, left, right, wait_time)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Recursive division\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mmid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mleft_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_and_create_summary_recurrsively\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Wait before processing the next half\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mright_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_and_create_summary_recurrsively\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmid\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-115-312375068bdf>\u001b[0m in \u001b[0;36mmerge_and_create_summary_recurrsively\u001b[0;34m(analysis_list, left, right, wait_time)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Recursive division\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mmid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mleft_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_and_create_summary_recurrsively\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Wait before processing the next half\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mright_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_and_create_summary_recurrsively\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmid\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-115-312375068bdf>\u001b[0m in \u001b[0;36mmerge_and_create_summary_recurrsively\u001b[0;34m(analysis_list, left, right, wait_time)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Recursive division\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mmid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mleft_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_and_create_summary_recurrsively\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Wait before processing the next half\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mright_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_and_create_summary_recurrsively\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmid\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-115-312375068bdf>\u001b[0m in \u001b[0;36mmerge_and_create_summary_recurrsively\u001b[0;34m(analysis_list, left, right, wait_time)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0msublist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalysis_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mright\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Introduce wait time before calling the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_final_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msublist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Recursive division\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-113-a0d2ddc4c283>\u001b[0m in \u001b[0;36mget_final_analysis\u001b[0;34m(analysis_list)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_final_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mevaluations_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_analysis_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mfinal_analysis\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgen_a_final_analysis_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluations_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3022\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3023\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3024\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/output_parsers/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m     ) -> T:\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m    194\u001b[0m                 lambda inner_input: self.parse_result(\n\u001b[1;32m    195\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mChatGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1923\u001b[0m             output = cast(\n\u001b[1;32m   1924\u001b[0m                 \u001b[0mOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1925\u001b[0;31m                 context.run(\n\u001b[0m\u001b[1;32m   1926\u001b[0m                     \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/output_parsers/base.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             return self._call_with_config(\n\u001b[0;32m--> 194\u001b[0;31m                 lambda inner_input: self.parse_result(\n\u001b[0m\u001b[1;32m    195\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mChatGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 ),\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/output_parsers/openai_tools.py\u001b[0m in \u001b[0;36mparse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m    296\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_tool_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpydantic_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpydantic_objects\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/output_parsers/openai_tools.py\u001b[0m in \u001b[0;36mparse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m    291\u001b[0m                     )\n\u001b[1;32m    292\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mpydantic_objects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValidationError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for PaperEvaluation\nevidenceScore.score\n  Input should be a valid integer, got a number with a fractional part [type=int_from_float, input_value=7.67, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.10/v/int_from_float\ntechnicalScore.score\n  Input should be a valid integer, got a number with a fractional part [type=int_from_float, input_value=8.67, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.10/v/int_from_float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WO533vFFTw8_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}